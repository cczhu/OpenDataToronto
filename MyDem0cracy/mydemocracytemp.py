import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as mpcm
import matplotlib.colors as mpcolor
import pylab
import pandas as pd
import os
import scipy
from datetime import datetime

df_votes = pd.read_csv("/home/cczhu/GitHub/OpenDataToronto/MyDem0cracy/data/votes.csv", sep=',', header=0, names=None, index_col=None)
df_hist = pd.read_csv("/home/cczhu/GitHub/OpenDataToronto/MyDem0cracy/data/stats-history.csv", sep=',', header=0, names=None, index_col=None)
df_comm = pd.read_csv("/home/cczhu/GitHub/OpenDataToronto/MyDem0cracy/data/comments.csv", sep=',', header=0, names=None, index_col=None)
df_part = pd.read_csv("/home/cczhu/GitHub/OpenDataToronto/MyDem0cracy/data/participants-votes.csv", sep=',', header=0, names=None, index_col=None)

# Do some preliminary pruning
df_hist.drop(["n-commenters", "n-voters"], axis=1, inplace=True)
df_part.drop("group-id", axis=1, inplace=True)

# Convert ms timestamps to datetime
df_votes["date"] = df_votes["timestamp"].apply(lambda x: datetime.fromtimestamp(x // 1000))
df_comm["date"] = df_comm["timestamp"].apply(lambda x: datetime.fromtimestamp(x // 1000))

df_comm.loc[df_comm["moderated"] == -1, :].head(10)


# From now on, let's restrict our consideration to allowed comments.  I'm not sure why comment-id 46 (or row 24) is so bad, so let's change it to "moderated" first before pruning.

# In[4]:

df_comm.at[24, "moderated"] = 1

drop_comments = df_comm.loc[df_comm["moderated"] == -1, "comment-id"].sort_values(inplace=False).reset_index(inplace=False, drop=True)
drop_comments = drop_comments.as_matrix().astype(str)
df_part.drop(drop_comments, axis=1, inplace=True)


# In[5]:

df_comm.drop(df_comm.loc[df_comm["moderated"] == -1].index.values, inplace=True)
df_comm.sort_values(by="comment-id", inplace=True)
df_comm.set_index("comment-id", drop=True, inplace=True)


# Weirdly, doing a value count on df_part gives a different result than the agree/disagree columns in df_comm!

# In[6]:

df_comm.loc[108,:]


# In[7]:

df_part["108"].value_counts()


# This isn't because of any of the analysis we did before (I checked the comment on the raw tables), so must be some mismatch between when the two .csvs were printed out.  I'll have to correct for this.

# In[8]:

# Haven't figured out a more Pythonic way of doing this...
df_comm.rename(columns={"agrees": "agrees_OLD", "disagrees": "disagrees_OLD"}, inplace=True)

neutral_temp = np.zeros(df_comm.shape[0], dtype=int)
agrees_temp = np.zeros(df_comm.shape[0], dtype=int)
disagrees_temp = np.zeros(df_comm.shape[0], dtype=int)

for i, item in enumerate(df_part.columns.values[5:]):
    counts = df_part[item].value_counts()
    if 1. in counts.index:
        agrees_temp[i] = counts[1.0]
    if -1. in counts.index:
        disagrees_temp[i] = counts[-1.0]
    if 0. in counts.index:
        neutral_temp[i] = counts[0.0]
        
df_comm["agrees"] = agrees_temp
df_comm["disagrees"] = disagrees_temp
df_comm["neutrals"] = neutral_temp


# <h1>Dataset Exploratory Analysis</h1>
# 
# <h2>Aggregate Numbers</h2>
# 
# How many comments, votes, and users are there?

# In[9]:

print("Number of comments", len(df_comm.index.unique()), "; Comment-id min:", df_comm.index.min(), " max:", df_comm.index.max())
print("Number of votes:", df_votes["timestamp"].count())
print("Number of users:", len(df_part["participant"].unique()), "; Participant id min:", df_part["participant"].min(), " max:", df_part["participant"].max())


# Comments are in chronological order, with some values skipped because we removed moderated comments.
# 
# <h2>Time Evolution</h2>
# 
# Over what period of time were comments submitted and votes cast?

# In[10]:

print("Date of first comment: ", df_comm["date"].min(), "; First vote: ", df_votes["date"].min())
print("Date of last comment: ", df_comm["date"].max(), "; Last vote: ", df_votes["date"].max())


# We can plot the cumulative number of comments vs. time.

# In[11]:


# So comments were made in spurts, suggesting individual users are making multiple comments.  We can test this by counting the number of instances when a user number repeats in the comments section.

# In[12]:

author_hist = df_comm["author-id"].value_counts()



# The survey was seeded by user 0, and overall the top five contributers built the lion's share of comments.

# In[14]:

print("Fraction of comments generated by top five commenters: {0:.1f}%".format(100*sum(author_hist[:5])/author_hist.sum()))


# The date a question was submitted must be directly proportional to how many votes were cast for it, since it could only be voted on after it was submitted!  Let's plot that.  (I calculate the mean and stdev below; I'll discuss those in a bit!)

# In[15]:

# Derive question count, mean, deviation from df_part.  np.mean, np.std ignore NaNs
dfp_q = pd.DataFrame([df_part.count(), df_part.apply(np.mean, axis=0), df_part.apply(np.std, axis=0)]).T
dfp_q.columns = ["count", "mean", "stdev"]
dfp_q.drop(["participant", "n-comments", "n-votes", "n-agree", "n-disagree"], inplace=True)
dfp_q.index = dfp_q.index.values.astype(int)

# Include dates
dfp_q["date"] = df_comm["date"]
dfp_q["days before close"] = (dfp_q.loc[dfp_q.index.max(), "date"] - dfp_q["date"]).as_matrix()/np.timedelta64(1,'D')


# In[16]:

plt.figure(figsize=[10,6])
plt.plot(dfp_q["days before close"], dfp_q["count"], 'bo')
plt.xlim([-1, 20]); plt.xlabel("Number of Days Question is Available"); plt.ylabel("Number of Votes"); plt.title("Number of Votes per Comment vs. Number of Days it was Available for Voting", y=1.03);


# There's a clear linear trend in this data, with the scatter being some measure of user participation rates.  A measure of the "quality" of a question would be "response fraction", the number of votes the question got divided by the total number of voter who visited the site after the question was posted.  The absolute number of votes cast, however, is still important, since a low number of votes will increase uncertainty.

# In[17]:

dfh_v = df_hist.groupby("n-comments").max()
# Includes the author of the comment (hence +1)
dfh_v["visitors since upload"] = len(df_part["participant"].unique()) - dfh_v["n-visitors"] + 1
dfh_v.drop(drop_comments.astype(int), inplace=True)





Useful stuff:
http://stats.stackexchange.com/questions/35185/dimensionality-reduction-svd-or-pca-on-a-large-sparse-matrix
http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/2698#2698
http://stats.stackexchange.com/questions/217995/what-is-an-intuitive-explanation-for-how-pca-turns-from-a-geometric-problem-wit




def get_top_remarks(X, labels, comments=df_comm["comment-body"], topcomm=3):
    
    for item in np.unique(labels):
        print("For cluster {0:d}".format(item))
        uvote_sub = uvote[labels == item]
        dfsr = pd.DataFrame([uvote_sub.apply(np.mean, axis=0), uvote_sub.apply(np.std, axis=0)]).T
        dfsr.columns = ["mean", "stdev"]
        dfsr.index = dfsr.index.values.astype(int)
        dfsr['text'] = comments
        dfsr.sort_values(by="mean", inplace=True, ascending=False)
        print("Top {0:d} comments:".format(topcomm))
        print(dfsr[["mean", "stdev", "text"]].head(topcomm))
        print("Bottom {0:d} comments:".format(topcomm))
        print(dfsr[["mean", "stdev", "text"]].tail(topcomm))
